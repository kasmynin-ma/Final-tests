**Подведите результаты эксперимента в экселе по следующим данным: ab_stats.csv - Google Диск:
Стат значимо ли отличается ARPPU в двух группах ? Какие рекомендации дадите
менеджеру?**

---

https://docs.google.com/spreadsheets/d/1VcAeWtrkQviKoSBYoK9lmIaU5-Qb2Pdj/edit?gid=1493066266#gid=1493066266

Названия строк |	Количество по полю ARPPU
|--------------|----------------------------|
| A              |	11835                   |
| B              |  11817                   |
| (пусто)        |  0                       |	
| Общий итог     |	23652                   |

 t-тест в Excel показал значение **0,642546897**, это означает, что p-значение больше стандартного уровня значимости (обычно 0,05). Вот несколько рекомендаций для менеджера: 
 
1. **Не отклонять нулевую гипотезу**: Поскольку p-значение высокое, это говорит о том, что нет достаточных оснований для отклонения нулевой гипотезы. Это может означать, что между сравниваемыми группами нет статистически значимой разницы. 
 
2. **Провести дополнительный анализ**: Рассмотреть возможность использования других статистических методов или дополнительных тестов, чтобы подтвердить или опровергнуть полученные результаты. Например, можно рассмотреть анализ ANOVA. 
 
3. **Обсудить результаты с командой**: Обсудить возможные причины, почему не было найдено статистически значимой разницы. 
 
4. **Планировать дальнейшие действия**: Можно планировать дальнейшие действия, например, улучшение процессов или изменение стратегии.

---
**Мы хотим провести А/Б-тест для трех источников трафика. Нынешняя конверсия равна 5%,
мы ожидаем прирост в 0,2%. Уровень доверия 97% и уровень мощности 87%. Всего на наш продукт заходит 40 000 пользователей в месяц.**

* За сколько дней мы сможем протестировать гипотезу? И что вы можете посоветовать по
результатам подсчета?

* Допустим в задаче нет проблемы с количеством посетителей на сайт, тогда подведите
результаты тестирования, если у нас следующие результаты по количеству конверсии:

1) 25 000
2) 30 000
3) 32 000

---
Для проведения А/Б-теста с заданными параметрами, необходимо рассчитать, сколько времени потребуется для достижения статистической значимости. 

### 1. Расчет необходимого объема выборки и времени

```import scipy.stats as stats

# Исходные данные
p1 = 0.05  # Текущая конверсия
p2 = 0.052  # Ожидаемая конверсия
alpha = 0.03  # Уровень доверия
beta = 0.13  # Уровень ошибки второго рода

# Z-значения
z_alpha = stats.norm.ppf(1 - alpha / 2)
z_beta = stats.norm.ppf(1 - beta)

# Размер выборки
n = ((z_alpha + z_beta) ** 2 * (p1 * (1 - p1) + p2 * (1 - p2))) / ((p2 - p1) ** 2)

n3 = n * 3

# Общее количество пользователей в месяц
total_users_per_month = 40000

# Количество дней для тестирования
days_to_test = (n3 / total_users_per_month) * 30  # 30 дней в месяце

print(f"Необходимый размер выборки для каждой группы: {n:.2f}")
print(f"Поскольку три источника трафика, общее количество пользователей, необходимое для теста: {n3:.2f}")
print(f"Количество дней для тестирования при общем количестве посетителей в месяц 40 000 человек:: {days_to_test:.2f}")
```

Необходимый размер выборки для каждой группы: 262965.46
Поскольку три источника трафика, общее количество пользователей, необходимое для теста: 788896.38
Количество дней для тестирования при общем количестве посетителей в месяц 40 000 человек: 591.67

-------------------------
Тратить на тест столько времени крайне неэффективно и непрактично. Вот несколько рекомендаций: 
 
1. **Пересмотр ожидаемого прироста конверсии**: Попробовать оценить, насколько реалистичен этот прирост и можно ли его увеличить. 
 
2. **Увеличение объема трафика**: Если возможно, увеличить общий объем трафика, направляемого на продукт. Это может быть сделано за счет маркетинговых кампаний, рекламы или других источников трафика. 
 
3. **Объединить источники трафика**: Вместо того чтобы тестировать каждый источник трафика отдельно, можно рассмотреть возможность объединения их в одну группу для тестирования. Это может помочь сократить необходимый размер выборки. 
 
4. **Использовать дополнительные метрики**: Вместо того чтобы полагаться только на конверсию, рассмотреть возможность использования других метрик, таких как средний доход на пользователя (ARPU) или удержание пользователей, для оценки успешности источников трафика.

   ---
Если нет проблемы с посетителями на сайте и результаты конверсии

1) 25 000
2) 30 000
3) 32 000

```import numpy as np
import statsmodels.api as sm

# Исходные данные
current_conversion_rate = 0.05  # Текущая конверсия
expected_increase = 0.002  # Ожидаемый прирост
n_users = 40000  # Общее количество пользователей

# Результаты по количеству конверсий
conversions = [25000, 30000, 32000]
conversion_rates = [conv / n_users for conv in conversions]

# Уровни доверия и мощности
confidence_level = 0.97
power = 0.87

# Функция для проведения A/B теста
def ab_test(conversion_rate_a, conversion_rate_b, n_a, n_b):
    # Преобразование в количество конверсий
    successes_a = conversion_rate_a * n_a
    successes_b = conversion_rate_b * n_b
    
    # Проводим тест
    z_score, p_value = sm.stats.proportions_ztest([successes_a, successes_b], [n_a, n_b])
    return z_score, p_value

# Проверяем результаты для каждой пары
results = []
for i in range(len(conversion_rates)):
    for j in range(i + 1, len(conversion_rates)):
        z_score, p_value = ab_test(conversion_rates[i], conversion_rates[j], n_users, n_users)
        results.append((i + 1, j + 1, z_score, p_value))

# Выводим результаты
for result in results:
    group_a, group_b, z_score, p_value = result
    print(f'Сравнение группы {group_a} и группы {group_b}:')
    print(f'Z-статистика: {z_score:.4f}, p-значение: {p_value:.4f}')
    if p_value < (1 - confidence_level):
        print('Результаты статистически значимы.\n')
    else:
        print('Результаты не являются статистически значимыми.\n')
```

--------------------------------------------------------------------------------
Сравнение группы 1 и группы 2:
Z-статистика: -38.1385, p-значение: 0.0000
Результаты статистически значимы.

Сравнение группы 1 и группы 3:
Z-статистика: -54.6817, p-значение: 0.0000
Результаты статистически значимы.

Сравнение группы 2 и группы 3:
Z-статистика: -16.9334, p-значение: 0.0000
Результаты статистически значимы.

------------------------------------------------

**Важны все три источника траффика**

---

**Вы решили сравнивать метрику CPA в двух группах. Размер выборки - 2350 элементов в
каждой группе.
Для проверки нормальности распределения на выборке в 2350 наблюдений применили ,
критерий Шапиро-Уилка и получили p-value, равный 0.00002, alpha = 5%.
Какой бы вывод мы могли сделать в данном случае?
В этом случае какой статистический критерий для проверки первоначальной гипотезы тут лучше
всего подойдёт и почему ?**

---
   
1. **Вывод по p-value**:  
   - p-value = 0.00002, что значительно меньше alpha = 0.05. Это означает, что отвергаем нулевую гипотезу о нормальности распределения. То есть, распределение данных не является нормальным. 
 
2. **Выбор статистического критерия**: 
   - Поскольку данные не распределены нормально, следует использовать непараметрические методы для сравнения двух групп. 
   - Тест Манна-Уитни не требует предположений о нормальности распределения и позволяет сравнивать медианы двух независимых выборок.
  
---

**Мы провели АБ-тест на увеличение average timespent per user. По итогам тестирования мы
получили следующие данные. Является ли результат статистически значимым с уровнем
доверия 80%? Какую версию мы выкатим на продакшн?

A) Средняя - 360, отклонение - 40, количество - 9802
B) Средняя - 352, отклонение - 58, количество - 9789**

---

```import numpy as np
from scipy import stats

# Данные для группы A
mean_A = 360
std_A = 40
n_A = 9802

# Данные для группы B
mean_B = 352
std_B = 58
n_B = 9789

# Стандартная ошибка для каждой группы
se_A = std_A / np.sqrt(n_A)
se_B = std_B / np.sqrt(n_B)

# Объединенная стандартная ошибка
se_combined = np.sqrt(se_A**2 + se_B**2)

# Разница в средних
mean_diff = mean_A - mean_B

# t-статистика
t_stat = mean_diff / se_combined

# Степени свободы
df = n_A + n_B - 2

# p-значение
p_value = 1 - stats.t.cdf(t_stat, df)

# Уровень доверия 80%
alpha = 0.2

# Проверка на статистическую значимость
is_significant = p_value < alpha

print(f"t-статистика: {t_stat}")
print(f"p-значение: {p_value}")
print(f"Статистически значимый результат: {'Да' if is_significant else 'Нет'}")

# Рекомендуемая версия для продакшн
if mean_A > mean_B:
    print("Рекомендуемая версия для продакшн: A")
else:
    print("Рекомендуемая версия для продакшн: B")
```

---

t-статистика: 11.236630785707332
p-значение: 0.0
Статистически значимый результат: Да
Рекомендуемая версия для продакшн: A

---

**Создайте техническую архитектуру проекта по аб тестированию продукта он-лайн кинотеатра
с учетом кросс-девайс аналитики по следующей гипотезе:
Если договориться с банком о 99% кэшбэке на подписку первого месяца, то это повысит
конверсию в подписку на 30%, благодаря упрощенному принятию решения со стороны
пользователя.**
На схеме необходимо отобразить:
1) Управленческий процесс по договоренностям с внешними партнерами
2) Архитектуру данных с указанием систем, из которых будем скачивать данные
3) Внутрикомандное взаимодействие

---

https://drive.google.com/file/d/1x7pwjnEf8kdsuCmbSnT7RXxzIjJZw-RL/view?usp=sharing
